# Clearing
# ==============================================================================
rm(list=ls()) # Clearing variables
graphics.off() # Clearing plotting devices
cat("\014") # Clearing console
# ==============================================================================

# Loading functions
# ==============================================================================
source("Aux_pdfsExtractor.R")
# ==============================================================================

# Function for LDA analysis
LDA_analysis <- function(nbtopics = NULL) {
  
  # Get input files
  pdfsFolderPath <- file.path(getwd(), "Inputs/PDFs")
  pdfsPaths <- list.files(pdfsFolderPath, pattern="*.pdf", full.names=TRUE)
  
  # Delete old output files
  unlink("3. LDA/*")
  
  # Initialize vectors and lists
  outFullList <- list()
  pdfNames <- c()
  
  # Data extraction and preprocessing
  for (i in pdfsPaths) {
    cleanDt <- fullCleanWords_stopWRemoved(i, "english")
    outFullList <- append(outFullList, list(cleanDt))
    pdfNames <- c(pdfNames, tools::file_path_sans_ext(basename(i)))
  }
  
  # Create a corpus
  allDataCorpus <- Corpus(VectorSource(outFullList))
  
  # Create a document term matrix
  docTerm <- DocumentTermMatrix(allDataCorpus, 
                                control = list(removePunctuation = TRUE,
                                               stopwords = TRUE,
                                               tolower = TRUE,
                                               stemming = TRUE,
                                               removeNumbers = TRUE
                                )) 
  
  # LDA model generation
  ldaModel <- LDA(docTerm, k = nbtopics, control = list(seed = 1234))
  
  # Compute word-topic probabilities
  topic_term_beta <- tidy(ldaModel, matrix = "beta")
  
  # Select top terms
  top_n_beta <- topic_term_beta %>%
    group_by(topic) %>%
    slice_max(beta, n = 8) %>% 
    ungroup() %>%
    arrange(topic, -beta)
  
  # Plot top terms
  plot_n_beta <- top_n_beta %>%
    mutate(term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(beta, term, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free") +
    scale_y_reordered() + scale_color_viridis(discrete = TRUE, option = "D")+
    scale_fill_viridis(discrete = TRUE) +
    labs(title = "Word-Topic Prob") +
    theme(
      plot.title = element_text(color = "#0099f9", size = 8, face ="bold", 
                                hjust = 0.5),
      axis.text.x=element_text(size=4),
      axis.text.y=element_text(size=4),
      axis.title=element_text(size=4,face="bold"),
      strip.text = element_text(size=5)
    ) 
  
  print(plot_n_beta)
  
  # Save plot
  png(file = paste("3. LDA/Word-Topic Prob.png"), width = 3.5, height = 2.5, 
      units = "in", res = 1100, pointsize = 4)
  print(plot_n_beta)
  dev.off()
  
  # Compute document-topic probabilities
  doc_topic_gamma <- tidy(ldaModel, matrix = "gamma")
  
  # Plot document-topic probabilities
  plot_doc_topic_gamma <-  doc_topic_gamma %>%
    mutate(title = reorder(document, gamma * topic)) %>%
    ggplot(aes(factor(topic), gamma)) +
    geom_boxplot() +
    facet_wrap(~ title) +
    labs(title = "Doc-Topic Prob", x = "topic", y = "Gamma")+
    theme(
      plot.title = element_text(color = "#0099f9", size = 8, face ="bold", 
                                hjust = 0.5),
      axis.text.x=element_text(size=4),
      axis.text.y=element_text(size=4),
      axis.title=element_text(size=4,face="bold"),
      strip.text = element_text(size=5)
    )
  
  print(plot_doc_topic_gamma)
  
  # Save plot
  png(file = paste("3. LDA/Doc-Topic Prob.png"), width = 3.5, height = 2.5, 
      units = "in", res = 1100, pointsize = 4)
  print(plot_doc_topic_gamma)
  dev.off()
  
  cat(green("Done!\n"))
}
